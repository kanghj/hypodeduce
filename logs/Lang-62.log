=== GPT-only pipeline for Lang-62 ===
  📊 GPT[hypothesis H1] tokens: 72 prompt + 43 completion = 115 total
  📊 GPT[hypothesis H2] tokens: 72 prompt + 42 completion = 114 total
  📊 GPT[hypothesis H3] tokens: 72 prompt + 41 completion = 113 total
  📊 GPT[hypothesis H4] tokens: 72 prompt + 42 completion = 114 total
  📊 GPT[hypothesis H5] tokens: 72 prompt + 41 completion = 113 total
  📊 GPT[hypothesis_confidence H1] tokens: 104 prompt + 3 completion = 107 total
  📊 GPT[hypothesis_confidence H2] tokens: 103 prompt + 3 completion = 106 total
  📊 GPT[hypothesis_confidence H3] tokens: 102 prompt + 3 completion = 105 total
  📊 GPT[hypothesis_confidence H4] tokens: 103 prompt + 3 completion = 106 total
  📊 GPT[hypothesis_confidence H5] tokens: 102 prompt + 3 completion = 105 total
Hypotheses:
  H1 (confidence 0.700): Hypothesis H1: The test "org.apache.commons.lang.EntitiesTest::testNumberOverflow" may be failing due to an integer overflow occurring when handling large numeric entity values, leading to incorrect parsing or encoding results.
  H2 (confidence 0.700): The test "org.apache.commons.lang.EntitiesTest::testNumberOverflow" might be failing due to incorrect handling or parsing of large numeric values that exceed the maximum limit supported by the data type used in the code.
  H3 (confidence 0.700): Hypothesis H3: The test "org.apache.commons.lang.EntitiesTest::testNumberOverflow" may be failing due to an incorrect handling of integer overflow when converting large numeric character references to their corresponding characters.
  H4 (confidence 0.700): Hypothesis H4: The test "org.apache.commons.lang.EntitiesTest::testNumberOverflow" may be failing due to an incorrect handling of integer overflow when converting large numeric entity references to their corresponding character representations.
  H5 (confidence 0.700): Hypothesis H5: The test "org.apache.commons.lang.EntitiesTest::testNumberOverflow" may be failing due to an incorrect handling of integer overflow when converting large numeric character references to their corresponding characters.
    ▶️ GPT[class pre-ranking] running 2 prompts
  📊 GPT[class_pre_rank org.apache.commons.lang.Entities] tokens: 589 prompt + 77 completion = 666 total
  📊 GPT[class_pre_rank org.apache.commons.lang.IntHashMap] tokens: 596 prompt + 74 completion = 670 total
    ✅ GPT[class pre-ranking] completed; taking top 5
Candidate classes:
  org.apache.commons.lang.Entities: n/a ```json
{"score": 0.9, "reason": "The failure occurs in the `Entities.unescape` method when handling numeric character references that exceed valid Unicode code points, as evidenced by the test expecting '&#12345678;' but receiving '慎'. The `Entities` class is responsible for entity utilities, making it the most likely location for the fix."}
```
  org.apache.commons.lang.IntHashMap: n/a ```json
{"score": 0.2, "reason": "The failure is related to handling numeric character references that exceed valid Unicode code points, which is more likely an issue in the `Entities` class rather than `IntHashMap`. The stack trace and test logic suggest the problem lies in the unescaping logic, not the hash map implementation."}
```
Collected 5 methods across candidate classes
    ▶️ GPT[method pre-ranking] running 5 prompts
  📊 GPT[method_pre_rank org.apache.commons.lang.Entities.unescape(String)] tokens: 754 prompt + 83 completion = 837 total
  📊 GPT[method_pre_rank org.apache.commons.lang.IntHashMap.IntHashMap()] tokens: 589 prompt + 67 completion = 656 total
  📊 GPT[method_pre_rank org.apache.commons.lang.IntHashMap.IntHashMap(int,float)] tokens: 591 prompt + 59 completion = 650 total
  📊 GPT[method_pre_rank org.apache.commons.lang.IntHashMap.put(int,Object)] tokens: 618 prompt + 57 completion = 675 total
  📊 GPT[method_pre_rank org.apache.commons.lang.IntHashMap.rehash()] tokens: 594 prompt + 67 completion = 661 total
    ✅ GPT[method pre-ranking] completed
Selected 5 candidate methods
  📊 GPT[class_score org.apache.commons.lang.Entities H1] tokens: 359 prompt + 3 completion = 362 total
  📊 GPT[class_explanation org.apache.commons.lang.Entities H1] tokens: 336 prompt + 105 completion = 441 total
  📊 GPT[class_score org.apache.commons.lang.IntHashMap H1] tokens: 374 prompt + 3 completion = 377 total
  📊 GPT[class_explanation org.apache.commons.lang.IntHashMap H1] tokens: 351 prompt + 129 completion = 480 total
  📊 GPT[class_score org.apache.commons.lang.Entities H2] tokens: 358 prompt + 3 completion = 361 total
  📊 GPT[class_explanation org.apache.commons.lang.Entities H2] tokens: 335 prompt + 115 completion = 450 total
  📊 GPT[class_score org.apache.commons.lang.IntHashMap H2] tokens: 373 prompt + 3 completion = 376 total
  📊 GPT[class_explanation org.apache.commons.lang.IntHashMap H2] tokens: 350 prompt + 119 completion = 469 total
  📊 GPT[class_score org.apache.commons.lang.Entities H3] tokens: 357 prompt + 3 completion = 360 total
  📊 GPT[class_explanation org.apache.commons.lang.Entities H3] tokens: 334 prompt + 105 completion = 439 total
  📊 GPT[class_score org.apache.commons.lang.IntHashMap H3] tokens: 372 prompt + 3 completion = 375 total
  📊 GPT[class_explanation org.apache.commons.lang.IntHashMap H3] tokens: 349 prompt + 127 completion = 476 total
  📊 GPT[class_score org.apache.commons.lang.Entities H4] tokens: 358 prompt + 3 completion = 361 total
  📊 GPT[class_explanation org.apache.commons.lang.Entities H4] tokens: 335 prompt + 103 completion = 438 total
  📊 GPT[class_score org.apache.commons.lang.IntHashMap H4] tokens: 373 prompt + 3 completion = 376 total
  📊 GPT[class_explanation org.apache.commons.lang.IntHashMap H4] tokens: 350 prompt + 125 completion = 475 total
  📊 GPT[class_score org.apache.commons.lang.Entities H5] tokens: 357 prompt + 3 completion = 360 total
  📊 GPT[class_explanation org.apache.commons.lang.Entities H5] tokens: 334 prompt + 121 completion = 455 total
  📊 GPT[class_score org.apache.commons.lang.IntHashMap H5] tokens: 372 prompt + 3 completion = 375 total
  📊 GPT[class_explanation org.apache.commons.lang.IntHashMap H5] tokens: 349 prompt + 134 completion = 483 total
  📊 GPT[method_score org.apache.commons.lang.Entities.unescape(String) H1] tokens: 597 prompt + 3 completion = 600 total
  📊 GPT[method_explanation org.apache.commons.lang.Entities.unescape(String) H1] tokens: 480 prompt + 141 completion = 621 total
  📊 GPT[method_score org.apache.commons.lang.IntHashMap.put(int,Object) H1] tokens: 432 prompt + 3 completion = 435 total
  📊 GPT[method_explanation org.apache.commons.lang.IntHashMap.put(int,Object) H1] tokens: 403 prompt + 126 completion = 529 total
  📊 GPT[method_score org.apache.commons.lang.IntHashMap.IntHashMap() H1] tokens: 403 prompt + 3 completion = 406 total
  📊 GPT[method_explanation org.apache.commons.lang.IntHashMap.IntHashMap() H1] tokens: 378 prompt + 100 completion = 478 total
  📊 GPT[method_score org.apache.commons.lang.IntHashMap.IntHashMap(int,float) H1] tokens: 405 prompt + 3 completion = 408 total
  📊 GPT[method_explanation org.apache.commons.lang.IntHashMap.IntHashMap(int,float) H1] tokens: 379 prompt + 105 completion = 484 total
  📊 GPT[method_score org.apache.commons.lang.IntHashMap.rehash() H1] tokens: 408 prompt + 3 completion = 411 total
  📊 GPT[method_explanation org.apache.commons.lang.IntHashMap.rehash() H1] tokens: 383 prompt + 122 completion = 505 total
  📊 GPT[method_score org.apache.commons.lang.Entities.unescape(String) H2] tokens: 596 prompt + 3 completion = 599 total
  📊 GPT[method_explanation org.apache.commons.lang.Entities.unescape(String) H2] tokens: 479 prompt + 139 completion = 618 total
  📊 GPT[method_score org.apache.commons.lang.IntHashMap.put(int,Object) H2] tokens: 431 prompt + 3 completion = 434 total
  📊 GPT[method_explanation org.apache.commons.lang.IntHashMap.put(int,Object) H2] tokens: 402 prompt + 108 completion = 510 total
  📊 GPT[method_score org.apache.commons.lang.IntHashMap.IntHashMap() H2] tokens: 402 prompt + 3 completion = 405 total
  📊 GPT[method_explanation org.apache.commons.lang.IntHashMap.IntHashMap() H2] tokens: 377 prompt + 102 completion = 479 total
  📊 GPT[method_score org.apache.commons.lang.IntHashMap.IntHashMap(int,float) H2] tokens: 404 prompt + 3 completion = 407 total
  📊 GPT[method_explanation org.apache.commons.lang.IntHashMap.IntHashMap(int,float) H2] tokens: 378 prompt + 114 completion = 492 total
  📊 GPT[method_score org.apache.commons.lang.IntHashMap.rehash() H2] tokens: 407 prompt + 3 completion = 410 total
  📊 GPT[method_explanation org.apache.commons.lang.IntHashMap.rehash() H2] tokens: 382 prompt + 115 completion = 497 total
  📊 GPT[method_score org.apache.commons.lang.Entities.unescape(String) H3] tokens: 595 prompt + 3 completion = 598 total
  📊 GPT[method_explanation org.apache.commons.lang.Entities.unescape(String) H3] tokens: 478 prompt + 112 completion = 590 total
  📊 GPT[method_score org.apache.commons.lang.IntHashMap.put(int,Object) H3] tokens: 430 prompt + 3 completion = 433 total
  📊 GPT[method_explanation org.apache.commons.lang.IntHashMap.put(int,Object) H3] tokens: 401 prompt + 139 completion = 540 total
  📊 GPT[method_score org.apache.commons.lang.IntHashMap.IntHashMap() H3] tokens: 401 prompt + 3 completion = 404 total
  📊 GPT[method_explanation org.apache.commons.lang.IntHashMap.IntHashMap() H3] tokens: 376 prompt + 127 completion = 503 total
  📊 GPT[method_score org.apache.commons.lang.IntHashMap.IntHashMap(int,float) H3] tokens: 403 prompt + 3 completion = 406 total
  📊 GPT[method_explanation org.apache.commons.lang.IntHashMap.IntHashMap(int,float) H3] tokens: 377 prompt + 88 completion = 465 total
  📊 GPT[method_score org.apache.commons.lang.IntHashMap.rehash() H3] tokens: 406 prompt + 3 completion = 409 total
  📊 GPT[method_explanation org.apache.commons.lang.IntHashMap.rehash() H3] tokens: 381 prompt + 118 completion = 499 total
  📊 GPT[method_score org.apache.commons.lang.Entities.unescape(String) H4] tokens: 596 prompt + 3 completion = 599 total
  📊 GPT[method_explanation org.apache.commons.lang.Entities.unescape(String) H4] tokens: 479 prompt + 122 completion = 601 total
  📊 GPT[method_score org.apache.commons.lang.IntHashMap.put(int,Object) H4] tokens: 431 prompt + 3 completion = 434 total
  📊 GPT[method_explanation org.apache.commons.lang.IntHashMap.put(int,Object) H4] tokens: 402 prompt + 108 completion = 510 total
  📊 GPT[method_score org.apache.commons.lang.IntHashMap.IntHashMap() H4] tokens: 402 prompt + 3 completion = 405 total
  📊 GPT[method_explanation org.apache.commons.lang.IntHashMap.IntHashMap() H4] tokens: 377 prompt + 116 completion = 493 total
  📊 GPT[method_score org.apache.commons.lang.IntHashMap.IntHashMap(int,float) H4] tokens: 404 prompt + 3 completion = 407 total
  📊 GPT[method_explanation org.apache.commons.lang.IntHashMap.IntHashMap(int,float) H4] tokens: 378 prompt + 102 completion = 480 total
  📊 GPT[method_score org.apache.commons.lang.IntHashMap.rehash() H4] tokens: 407 prompt + 3 completion = 410 total
  📊 GPT[method_explanation org.apache.commons.lang.IntHashMap.rehash() H4] tokens: 382 prompt + 89 completion = 471 total
  📊 GPT[method_score org.apache.commons.lang.Entities.unescape(String) H5] tokens: 595 prompt + 3 completion = 598 total
  📊 GPT[method_explanation org.apache.commons.lang.Entities.unescape(String) H5] tokens: 478 prompt + 118 completion = 596 total
  📊 GPT[method_score org.apache.commons.lang.IntHashMap.put(int,Object) H5] tokens: 430 prompt + 3 completion = 433 total
  📊 GPT[method_explanation org.apache.commons.lang.IntHashMap.put(int,Object) H5] tokens: 401 prompt + 124 completion = 525 total
  📊 GPT[method_score org.apache.commons.lang.IntHashMap.IntHashMap() H5] tokens: 401 prompt + 3 completion = 404 total
  📊 GPT[method_explanation org.apache.commons.lang.IntHashMap.IntHashMap() H5] tokens: 376 prompt + 121 completion = 497 total
  📊 GPT[method_score org.apache.commons.lang.IntHashMap.IntHashMap(int,float) H5] tokens: 403 prompt + 3 completion = 406 total
  📊 GPT[method_explanation org.apache.commons.lang.IntHashMap.IntHashMap(int,float) H5] tokens: 377 prompt + 93 completion = 470 total
  📊 GPT[method_score org.apache.commons.lang.IntHashMap.rehash() H5] tokens: 406 prompt + 3 completion = 409 total
  📊 GPT[method_explanation org.apache.commons.lang.IntHashMap.rehash() H5] tokens: 381 prompt + 98 completion = 479 total

Top suspicious methods:
  1. org.apache.commons.lang.Entities.unescape(String): 0.900 — best hypothesis H1: Hypothesis H1: The test "org.apache.commons.lang.EntitiesTest::testNumberOverflow" may be failing due to an integer overflow occurring when handling large numeric entity values, leading to incorrect parsing or encoding results. (confidence 0.700); supporting class org.apache.commons.lang.Entities (HH3)
      explanation: The method `org.apache.commons.lang.Entities.unescape(String)` is likely contributing to the failure of the test `org.apache.commons.lang.EntitiesTest::testNumberOverflow` due to an integer overflow. The test case expects the string "&#1...
  2. org.apache.commons.lang.IntHashMap.put(int,Object): 0.200 — best hypothesis H1: Hypothesis H1: The test "org.apache.commons.lang.EntitiesTest::testNumberOverflow" may be failing due to an integer overflow occurring when handling large numeric entity values, leading to incorrect parsing or encoding results. (confidence 0.700); supporting class org.apache.commons.lang.IntHashMap (HH1)
      explanation: The method `org.apache.commons.lang.IntHashMap.put(int,Object)` does not directly support hypothesis H1, as it primarily deals with inserting or updating key-value pairs in a hash map rather than parsing or encoding numeric entity values...
  3. org.apache.commons.lang.IntHashMap.IntHashMap(): 0.200 — best hypothesis H1: Hypothesis H1: The test "org.apache.commons.lang.EntitiesTest::testNumberOverflow" may be failing due to an integer overflow occurring when handling large numeric entity values, leading to incorrect parsing or encoding results. (confidence 0.700); supporting class org.apache.commons.lang.IntHashMap (HH1)
      explanation: The method `org.apache.commons.lang.IntHashMap.IntHashMap()` initializes an `IntHashMap` with a default capacity and load factor, which does not directly handle or parse numeric entity values. Therefore, it neither supports nor contradic...
  4. org.apache.commons.lang.IntHashMap.IntHashMap(int,float): 0.200 — best hypothesis H5: Hypothesis H5: The test "org.apache.commons.lang.EntitiesTest::testNumberOverflow" may be failing due to an incorrect handling of integer overflow when converting large numeric character references to their corresponding characters. (confidence 0.700); supporting class org.apache.commons.lang.IntHashMap (HH1)
      explanation: The method `org.apache.commons.lang.IntHashMap.IntHashMap(int, float)` initializes an internal data structure with specified capacity and load factor, focusing on argument validation and setup. It does not directly handle numeric charact...
  5. org.apache.commons.lang.IntHashMap.rehash(): 0.200 — best hypothesis H1: Hypothesis H1: The test "org.apache.commons.lang.EntitiesTest::testNumberOverflow" may be failing due to an integer overflow occurring when handling large numeric entity values, leading to incorrect parsing or encoding results. (confidence 0.700); supporting class org.apache.commons.lang.IntHashMap (HH1)
      explanation: The method `org.apache.commons.lang.IntHashMap.rehash()` is primarily concerned with resizing and redistributing entries within the hash map to maintain performance as the map grows. It does not directly handle numeric entity values or p...

📊 Token Usage Summary:
  Total API calls: 87
  Total tokens: 38,404
  Prompt tokens: 33,561
  Completion tokens: 4,843
Results written to defects4j_batch_results/Lang-62_parallel_case/Lang-62_parallel_answer.csv
Token usage written to defects4j_batch_results/Lang-62_parallel_case/Lang-62_token_usage.csv
Summary written to defects4j_batch_results/Lang-62_parallel_case/Lang-62_parallel_summary.md

=== GPT-only pipeline for Lang-31 ===
  📊 GPT[hypothesis H1] tokens: 83 prompt + 34 completion = 117 total
  📊 GPT[hypothesis H2] tokens: 83 prompt + 36 completion = 119 total
  📊 GPT[hypothesis H3] tokens: 83 prompt + 35 completion = 118 total
  📊 GPT[hypothesis H4] tokens: 83 prompt + 40 completion = 123 total
  📊 GPT[hypothesis H5] tokens: 83 prompt + 35 completion = 118 total
  📊 GPT[hypothesis_confidence H1] tokens: 95 prompt + 3 completion = 98 total
  📊 GPT[hypothesis_confidence H2] tokens: 97 prompt + 3 completion = 100 total
  📊 GPT[hypothesis_confidence H3] tokens: 96 prompt + 3 completion = 99 total
  📊 GPT[hypothesis_confidence H4] tokens: 101 prompt + 3 completion = 104 total
  📊 GPT[hypothesis_confidence H5] tokens: 96 prompt + 3 completion = 99 total
Hypotheses:
  H1 (confidence 0.700): Hypothesis H1: The test failure may be caused by incorrect handling of supplementary Unicode characters in the `containsAny` method, leading to inaccurate character matching or indexing.
  H2 (confidence 0.700): Hypothesis H2: The test failure may be caused by incorrect handling or encoding of supplementary Unicode characters, leading to mismatches in character comparisons within the `containsAny` method.
  H3 (confidence 0.700): Hypothesis H3: The test failure may be caused by incorrect handling of surrogate pairs in the `containsAny` method when processing supplementary characters, leading to inaccurate character matching.
  H4 (confidence 0.800): Hypothesis H4: The failure may be caused by incorrect handling or comparison of supplementary characters in the `containsAny` method, leading to unexpected results when processing characters outside the Basic Multilingual Plane.
  H5 (confidence 0.700): Hypothesis H5: The test failure might be caused by incorrect handling of surrogate pairs in the `containsAny` method when processing supplementary characters, leading to inaccurate character matching.
    ▶️ GPT[class pre-ranking] running 2 prompts
  📊 GPT[class_pre_rank org.apache.commons.lang3.ArrayUtils] tokens: 793 prompt + 52 completion = 845 total
  📊 GPT[class_pre_rank org.apache.commons.lang3.StringUtils] tokens: 768 prompt + 46 completion = 814 total
    ✅ GPT[class pre-ranking] completed; taking top 5
Candidate classes:
  org.apache.commons.lang3.ArrayUtils: n/a ```json
{"score": 0.2, "reason": "The failure is related to handling supplementary characters in StringUtils.containsAny, not ArrayUtils.isEmpty. The bug likely resides in StringUtils, which processes character arrays and strings."}
```
  org.apache.commons.lang3.StringUtils: n/a ```json
{"score": 0.9, "reason": "The failures are directly related to the handling of supplementary characters in the StringUtils.containsAny methods, indicating a likely issue in these methods' logic."}
```
Collected 4 methods across candidate classes
    ▶️ GPT[method pre-ranking] running 4 prompts
  📊 GPT[method_pre_rank org.apache.commons.lang3.ArrayUtils.isEmpty(char[])] tokens: 860 prompt + 61 completion = 921 total
  📊 GPT[method_pre_rank org.apache.commons.lang3.StringUtils.containsAny(CharSequence,String)] tokens: 841 prompt + 59 completion = 900 total
  📊 GPT[method_pre_rank org.apache.commons.lang3.StringUtils.containsAny(CharSequence,char[])] tokens: 915 prompt + 68 completion = 983 total
  📊 GPT[method_pre_rank org.apache.commons.lang3.StringUtils.isEmpty(CharSequence)] tokens: 754 prompt + 46 completion = 800 total
    ✅ GPT[method pre-ranking] completed
Selected 4 candidate methods
  📊 GPT[class_score org.apache.commons.lang3.ArrayUtils H1] tokens: 553 prompt + 3 completion = 556 total
  📊 GPT[class_explanation org.apache.commons.lang3.ArrayUtils H1] tokens: 533 prompt + 140 completion = 673 total
  📊 GPT[class_score org.apache.commons.lang3.StringUtils H1] tokens: 567 prompt + 3 completion = 570 total
  📊 GPT[class_explanation org.apache.commons.lang3.StringUtils H1] tokens: 546 prompt + 108 completion = 654 total
  📊 GPT[class_score org.apache.commons.lang3.ArrayUtils H2] tokens: 555 prompt + 3 completion = 558 total
  📊 GPT[class_explanation org.apache.commons.lang3.ArrayUtils H2] tokens: 535 prompt + 101 completion = 636 total
  📊 GPT[class_score org.apache.commons.lang3.StringUtils H2] tokens: 569 prompt + 3 completion = 572 total
  📊 GPT[class_explanation org.apache.commons.lang3.StringUtils H2] tokens: 548 prompt + 128 completion = 676 total
  📊 GPT[class_score org.apache.commons.lang3.ArrayUtils H3] tokens: 554 prompt + 3 completion = 557 total
  📊 GPT[class_explanation org.apache.commons.lang3.ArrayUtils H3] tokens: 534 prompt + 103 completion = 637 total
  📊 GPT[class_score org.apache.commons.lang3.StringUtils H3] tokens: 568 prompt + 3 completion = 571 total
  📊 GPT[class_explanation org.apache.commons.lang3.StringUtils H3] tokens: 547 prompt + 119 completion = 666 total
  📊 GPT[class_score org.apache.commons.lang3.ArrayUtils H4] tokens: 559 prompt + 3 completion = 562 total
  📊 GPT[class_explanation org.apache.commons.lang3.ArrayUtils H4] tokens: 539 prompt + 122 completion = 661 total
  📊 GPT[class_score org.apache.commons.lang3.StringUtils H4] tokens: 573 prompt + 3 completion = 576 total
  📊 GPT[class_explanation org.apache.commons.lang3.StringUtils H4] tokens: 552 prompt + 123 completion = 675 total
  📊 GPT[class_score org.apache.commons.lang3.ArrayUtils H5] tokens: 554 prompt + 3 completion = 557 total
  📊 GPT[class_explanation org.apache.commons.lang3.ArrayUtils H5] tokens: 534 prompt + 114 completion = 648 total
  📊 GPT[class_score org.apache.commons.lang3.StringUtils H5] tokens: 568 prompt + 3 completion = 571 total
  📊 GPT[class_explanation org.apache.commons.lang3.StringUtils H5] tokens: 547 prompt + 116 completion = 663 total
  📊 GPT[method_score org.apache.commons.lang3.ArrayUtils.isEmpty(char[]) H1] tokens: 649 prompt + 3 completion = 652 total
  📊 GPT[method_explanation org.apache.commons.lang3.ArrayUtils.isEmpty(char[]) H1] tokens: 630 prompt + 106 completion = 736 total
  📊 GPT[method_score org.apache.commons.lang3.StringUtils.containsAny(CharSequence,String) H1] tokens: 683 prompt + 3 completion = 686 total
  📊 GPT[method_explanation org.apache.commons.lang3.StringUtils.containsAny(CharSequence,String) H1] tokens: 658 prompt + 102 completion = 760 total
  📊 GPT[method_score org.apache.commons.lang3.StringUtils.containsAny(CharSequence,char[]) H1] tokens: 788 prompt + 3 completion = 791 total
  📊 GPT[method_explanation org.apache.commons.lang3.StringUtils.containsAny(CharSequence,char[]) H1] tokens: 666 prompt + 115 completion = 781 total
  📊 GPT[method_score org.apache.commons.lang3.StringUtils.isEmpty(CharSequence) H1] tokens: 592 prompt + 3 completion = 595 total
  📊 GPT[method_explanation org.apache.commons.lang3.StringUtils.isEmpty(CharSequence) H1] tokens: 569 prompt + 89 completion = 658 total
  📊 GPT[method_score org.apache.commons.lang3.ArrayUtils.isEmpty(char[]) H2] tokens: 651 prompt + 3 completion = 654 total
  📊 GPT[method_explanation org.apache.commons.lang3.ArrayUtils.isEmpty(char[]) H2] tokens: 632 prompt + 120 completion = 752 total
  📊 GPT[method_score org.apache.commons.lang3.StringUtils.containsAny(CharSequence,String) H2] tokens: 685 prompt + 3 completion = 688 total
  📊 GPT[method_explanation org.apache.commons.lang3.StringUtils.containsAny(CharSequence,String) H2] tokens: 660 prompt + 129 completion = 789 total
  📊 GPT[method_score org.apache.commons.lang3.StringUtils.containsAny(CharSequence,char[]) H2] tokens: 790 prompt + 3 completion = 793 total
  📊 GPT[method_explanation org.apache.commons.lang3.StringUtils.containsAny(CharSequence,char[]) H2] tokens: 668 prompt + 103 completion = 771 total
  📊 GPT[method_score org.apache.commons.lang3.StringUtils.isEmpty(CharSequence) H2] tokens: 594 prompt + 3 completion = 597 total
  📊 GPT[method_explanation org.apache.commons.lang3.StringUtils.isEmpty(CharSequence) H2] tokens: 571 prompt + 106 completion = 677 total
  📊 GPT[method_score org.apache.commons.lang3.ArrayUtils.isEmpty(char[]) H3] tokens: 650 prompt + 3 completion = 653 total
  📊 GPT[method_explanation org.apache.commons.lang3.ArrayUtils.isEmpty(char[]) H3] tokens: 631 prompt + 115 completion = 746 total
  📊 GPT[method_score org.apache.commons.lang3.StringUtils.containsAny(CharSequence,String) H3] tokens: 684 prompt + 3 completion = 687 total
  📊 GPT[method_explanation org.apache.commons.lang3.StringUtils.containsAny(CharSequence,String) H3] tokens: 659 prompt + 100 completion = 759 total
  📊 GPT[method_score org.apache.commons.lang3.StringUtils.containsAny(CharSequence,char[]) H3] tokens: 789 prompt + 3 completion = 792 total
  📊 GPT[method_explanation org.apache.commons.lang3.StringUtils.containsAny(CharSequence,char[]) H3] tokens: 667 prompt + 111 completion = 778 total
  📊 GPT[method_score org.apache.commons.lang3.StringUtils.isEmpty(CharSequence) H3] tokens: 593 prompt + 3 completion = 596 total
  📊 GPT[method_explanation org.apache.commons.lang3.StringUtils.isEmpty(CharSequence) H3] tokens: 570 prompt + 96 completion = 666 total
  📊 GPT[method_score org.apache.commons.lang3.ArrayUtils.isEmpty(char[]) H4] tokens: 655 prompt + 3 completion = 658 total
  📊 GPT[method_explanation org.apache.commons.lang3.ArrayUtils.isEmpty(char[]) H4] tokens: 636 prompt + 100 completion = 736 total
  📊 GPT[method_score org.apache.commons.lang3.StringUtils.containsAny(CharSequence,String) H4] tokens: 689 prompt + 3 completion = 692 total
  📊 GPT[method_explanation org.apache.commons.lang3.StringUtils.containsAny(CharSequence,String) H4] tokens: 664 prompt + 128 completion = 792 total
  📊 GPT[method_score org.apache.commons.lang3.StringUtils.containsAny(CharSequence,char[]) H4] tokens: 794 prompt + 3 completion = 797 total
  📊 GPT[method_explanation org.apache.commons.lang3.StringUtils.containsAny(CharSequence,char[]) H4] tokens: 672 prompt + 139 completion = 811 total
  📊 GPT[method_score org.apache.commons.lang3.StringUtils.isEmpty(CharSequence) H4] tokens: 598 prompt + 3 completion = 601 total
  📊 GPT[method_explanation org.apache.commons.lang3.StringUtils.isEmpty(CharSequence) H4] tokens: 575 prompt + 112 completion = 687 total
  📊 GPT[method_score org.apache.commons.lang3.ArrayUtils.isEmpty(char[]) H5] tokens: 650 prompt + 3 completion = 653 total
  📊 GPT[method_explanation org.apache.commons.lang3.ArrayUtils.isEmpty(char[]) H5] tokens: 631 prompt + 106 completion = 737 total
  📊 GPT[method_score org.apache.commons.lang3.StringUtils.containsAny(CharSequence,String) H5] tokens: 684 prompt + 3 completion = 687 total
  📊 GPT[method_explanation org.apache.commons.lang3.StringUtils.containsAny(CharSequence,String) H5] tokens: 659 prompt + 125 completion = 784 total
  📊 GPT[method_score org.apache.commons.lang3.StringUtils.containsAny(CharSequence,char[]) H5] tokens: 789 prompt + 3 completion = 792 total
  📊 GPT[method_explanation org.apache.commons.lang3.StringUtils.containsAny(CharSequence,char[]) H5] tokens: 667 prompt + 128 completion = 795 total
  📊 GPT[method_score org.apache.commons.lang3.StringUtils.isEmpty(CharSequence) H5] tokens: 593 prompt + 3 completion = 596 total
  📊 GPT[method_explanation org.apache.commons.lang3.StringUtils.isEmpty(CharSequence) H5] tokens: 570 prompt + 111 completion = 681 total

Top suspicious methods:
  1. org.apache.commons.lang3.StringUtils.containsAny(CharSequence,char[]): 0.900 — best hypothesis H1: Hypothesis H1: The test failure may be caused by incorrect handling of supplementary Unicode characters in the `containsAny` method, leading to inaccurate character matching or indexing. (confidence 0.700); supporting class org.apache.commons.lang3.StringUtils (HH1)
      explanation: The method `org.apache.commons.lang3.StringUtils.containsAny(CharSequence, char[])` checks if a CharSequence contains any character from a given set of characters. The test failure suggests that the method may not correctly handle supple...
  2. org.apache.commons.lang3.StringUtils.containsAny(CharSequence,String): 0.800 — best hypothesis H1: Hypothesis H1: The test failure may be caused by incorrect handling of supplementary Unicode characters in the `containsAny` method, leading to inaccurate character matching or indexing. (confidence 0.700); supporting class org.apache.commons.lang3.StringUtils (HH1)
      explanation: The method `org.apache.commons.lang3.StringUtils.containsAny(CharSequence, String)` converts the `searchChars` string into a character array and then calls `containsAny(CharSequence, char[])`. This process may not correctly handle supple...
  3. org.apache.commons.lang3.ArrayUtils.isEmpty(char[]): 0.100 — best hypothesis H1: Hypothesis H1: The test failure may be caused by incorrect handling of supplementary Unicode characters in the `containsAny` method, leading to inaccurate character matching or indexing. (confidence 0.700); supporting class org.apache.commons.lang3.ArrayUtils (HH1)
      explanation: The method `org.apache.commons.lang3.ArrayUtils.isEmpty(char[])` checks if a character array is null or has zero length, returning true in such cases. This method does not directly handle or process Unicode characters, including suppleme...
  4. org.apache.commons.lang3.StringUtils.isEmpty(CharSequence): 0.100 — best hypothesis H1: Hypothesis H1: The test failure may be caused by incorrect handling of supplementary Unicode characters in the `containsAny` method, leading to inaccurate character matching or indexing. (confidence 0.700); supporting class org.apache.commons.lang3.StringUtils (HH1)
      explanation: The method `org.apache.commons.lang3.StringUtils.isEmpty(CharSequence)` does not directly support or contradict Hypothesis H1, as it is unrelated to character matching or indexing. It simply checks if a CharSequence is null or empty, wit...

📊 Token Usage Summary:
  Total API calls: 76
  Total tokens: 47,153
  Prompt tokens: 43,121
  Completion tokens: 4,032
Results written to defects4j_batch_results/Lang-31_parallel_case/Lang-31_parallel_answer.csv
Token usage written to defects4j_batch_results/Lang-31_parallel_case/Lang-31_token_usage.csv
Summary written to defects4j_batch_results/Lang-31_parallel_case/Lang-31_parallel_summary.md

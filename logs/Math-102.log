=== GPT-only pipeline for Math-102 ===
  📊 GPT[hypothesis H1] tokens: 81 prompt + 29 completion = 110 total
  📊 GPT[hypothesis H2] tokens: 81 prompt + 36 completion = 117 total
  📊 GPT[hypothesis H3] tokens: 81 prompt + 31 completion = 112 total
  📊 GPT[hypothesis H4] tokens: 81 prompt + 31 completion = 112 total
  📊 GPT[hypothesis H5] tokens: 81 prompt + 30 completion = 111 total
  📊 GPT[hypothesis_confidence H1] tokens: 90 prompt + 3 completion = 93 total
  📊 GPT[hypothesis_confidence H2] tokens: 97 prompt + 3 completion = 100 total
  📊 GPT[hypothesis_confidence H3] tokens: 92 prompt + 3 completion = 95 total
  📊 GPT[hypothesis_confidence H4] tokens: 92 prompt + 3 completion = 95 total
  📊 GPT[hypothesis_confidence H5] tokens: 91 prompt + 3 completion = 94 total
Hypotheses:
  H1 (confidence 0.700): Hypothesis H1: The failure may be caused by incorrect handling of floating-point precision in the calculation of the chi-square statistic for large datasets.
  H2 (confidence 0.700): Hypothesis H2: The failure might be caused by incorrect assumptions or thresholds in the test case that do not account for edge cases or large input values, leading to unexpected results.
  H3 (confidence 0.700): Hypothesis H3: The failure may be caused by an incorrect implementation of the chi-square distribution calculation, leading to inaccurate test statistic values for large datasets.
  H4 (confidence 0.700): Hypothesis H4: The failure may be caused by an incorrect implementation of the chi-square distribution calculation, leading to inaccurate test statistic values for large datasets.
  H5 (confidence 0.700): Hypothesis H5: The failure may be caused by an incorrect implementation of the chi-square calculation algorithm, leading to inaccurate test statistics for large datasets.
Ignoring 21 covered classes without method coverage
    ▶️ GPT[class pre-ranking] running 2 prompts
  📊 GPT[class_pre_rank org.apache.commons.math.stat.inference.ChiSquareTestImpl] tokens: 824 prompt + 55 completion = 879 total
  📊 GPT[class_pre_rank org.apache.commons.math.stat.inference.TestUtils] tokens: 823 prompt + 49 completion = 872 total
    ✅ GPT[class pre-ranking] completed; taking top 5
Candidate classes:
  org.apache.commons.math.stat.inference.TestUtils: 0.800 {"score": 0.8, "reason": "The failure evidence indicates that the chi-square test statistic calculation in ChiSquareTestImpl is incorrect, suggesting a bug in the chiSquareTest method, which is part of TestUtils."}
  org.apache.commons.math.stat.inference.ChiSquareTestImpl: n/a ```json
{"score": 0.9, "reason": "The discrepancy in the chi-square test statistic suggests a calculation error in ChiSquareTestImpl. The class directly implements the chi-square test logic, making it the most likely location for the bug."}
```
Collected 4 methods across candidate classes
    ▶️ GPT[method pre-ranking] running 4 prompts
  📊 GPT[method_pre_rank org.apache.commons.math.stat.inference.ChiSquareTestImpl.chiSquare(double[],long[])] tokens: 939 prompt + 70 completion = 1009 total
  📊 GPT[method_pre_rank org.apache.commons.math.stat.inference.ChiSquareTestImpl.chiSquareTest(double[],long[])] tokens: 923 prompt + 65 completion = 988 total
  📊 GPT[method_pre_rank org.apache.commons.math.stat.inference.TestUtils.chiSquare(double[],long[])] tokens: 829 prompt + 81 completion = 910 total
  📊 GPT[method_pre_rank org.apache.commons.math.stat.inference.TestUtils.chiSquareTest(double[],long[])] tokens: 824 prompt + 69 completion = 893 total
    ✅ GPT[method pre-ranking] completed
Selected 4 candidate methods
  📊 GPT[class_score org.apache.commons.math.stat.inference.TestUtils H1] tokens: 586 prompt + 3 completion = 589 total
  📊 GPT[class_explanation org.apache.commons.math.stat.inference.TestUtils H1] tokens: 566 prompt + 116 completion = 682 total
  📊 GPT[class_score org.apache.commons.math.stat.inference.ChiSquareTestImpl H1] tokens: 589 prompt + 3 completion = 592 total
  📊 GPT[class_explanation org.apache.commons.math.stat.inference.ChiSquareTestImpl H1] tokens: 569 prompt + 139 completion = 708 total
  📊 GPT[class_score org.apache.commons.math.stat.inference.TestUtils H2] tokens: 593 prompt + 3 completion = 596 total
  📊 GPT[class_explanation org.apache.commons.math.stat.inference.TestUtils H2] tokens: 573 prompt + 148 completion = 721 total
  📊 GPT[class_score org.apache.commons.math.stat.inference.ChiSquareTestImpl H2] tokens: 596 prompt + 3 completion = 599 total
  📊 GPT[class_explanation org.apache.commons.math.stat.inference.ChiSquareTestImpl H2] tokens: 576 prompt + 152 completion = 728 total
  📊 GPT[class_score org.apache.commons.math.stat.inference.TestUtils H3] tokens: 588 prompt + 3 completion = 591 total
  📊 GPT[class_explanation org.apache.commons.math.stat.inference.TestUtils H3] tokens: 568 prompt + 127 completion = 695 total
  📊 GPT[class_score org.apache.commons.math.stat.inference.ChiSquareTestImpl H3] tokens: 591 prompt + 3 completion = 594 total
  📊 GPT[class_explanation org.apache.commons.math.stat.inference.ChiSquareTestImpl H3] tokens: 571 prompt + 137 completion = 708 total
  📊 GPT[class_score org.apache.commons.math.stat.inference.TestUtils H4] tokens: 588 prompt + 3 completion = 591 total
  📊 GPT[class_explanation org.apache.commons.math.stat.inference.TestUtils H4] tokens: 568 prompt + 135 completion = 703 total
  📊 GPT[class_score org.apache.commons.math.stat.inference.ChiSquareTestImpl H4] tokens: 591 prompt + 3 completion = 594 total
  📊 GPT[class_explanation org.apache.commons.math.stat.inference.ChiSquareTestImpl H4] tokens: 571 prompt + 120 completion = 691 total
  📊 GPT[class_score org.apache.commons.math.stat.inference.TestUtils H5] tokens: 587 prompt + 3 completion = 590 total
  📊 GPT[class_explanation org.apache.commons.math.stat.inference.TestUtils H5] tokens: 567 prompt + 129 completion = 696 total
  📊 GPT[class_score org.apache.commons.math.stat.inference.ChiSquareTestImpl H5] tokens: 590 prompt + 3 completion = 593 total
  📊 GPT[class_explanation org.apache.commons.math.stat.inference.ChiSquareTestImpl H5] tokens: 570 prompt + 117 completion = 687 total
  📊 GPT[method_score org.apache.commons.math.stat.inference.TestUtils.chiSquare(double[],long[]) H1] tokens: 635 prompt + 3 completion = 638 total
  📊 GPT[method_explanation org.apache.commons.math.stat.inference.TestUtils.chiSquare(double[],long[]) H1] tokens: 616 prompt + 105 completion = 721 total
  📊 GPT[method_score org.apache.commons.math.stat.inference.TestUtils.chiSquareTest(double[],long[]) H1] tokens: 627 prompt + 3 completion = 630 total
  📊 GPT[method_explanation org.apache.commons.math.stat.inference.TestUtils.chiSquareTest(double[],long[]) H1] tokens: 605 prompt + 138 completion = 743 total
  📊 GPT[method_score org.apache.commons.math.stat.inference.ChiSquareTestImpl.chiSquare(double[],long[]) H1] tokens: 792 prompt + 3 completion = 795 total
  📊 GPT[method_explanation org.apache.commons.math.stat.inference.ChiSquareTestImpl.chiSquare(double[],long[]) H1] tokens: 671 prompt + 132 completion = 803 total
  📊 GPT[method_score org.apache.commons.math.stat.inference.ChiSquareTestImpl.chiSquareTest(double[],long[]) H1] tokens: 728 prompt + 3 completion = 731 total
  📊 GPT[method_explanation org.apache.commons.math.stat.inference.ChiSquareTestImpl.chiSquareTest(double[],long[]) H1] tokens: 672 prompt + 130 completion = 802 total
  📊 GPT[method_score org.apache.commons.math.stat.inference.TestUtils.chiSquare(double[],long[]) H2] tokens: 642 prompt + 3 completion = 645 total
  📊 GPT[method_explanation org.apache.commons.math.stat.inference.TestUtils.chiSquare(double[],long[]) H2] tokens: 623 prompt + 123 completion = 746 total
  📊 GPT[method_score org.apache.commons.math.stat.inference.TestUtils.chiSquareTest(double[],long[]) H2] tokens: 634 prompt + 3 completion = 637 total
  📊 GPT[method_explanation org.apache.commons.math.stat.inference.TestUtils.chiSquareTest(double[],long[]) H2] tokens: 612 prompt + 136 completion = 748 total
  📊 GPT[method_score org.apache.commons.math.stat.inference.ChiSquareTestImpl.chiSquare(double[],long[]) H2] tokens: 799 prompt + 3 completion = 802 total
  📊 GPT[method_explanation org.apache.commons.math.stat.inference.ChiSquareTestImpl.chiSquare(double[],long[]) H2] tokens: 678 prompt + 130 completion = 808 total
  📊 GPT[method_score org.apache.commons.math.stat.inference.ChiSquareTestImpl.chiSquareTest(double[],long[]) H2] tokens: 735 prompt + 3 completion = 738 total
  📊 GPT[method_explanation org.apache.commons.math.stat.inference.ChiSquareTestImpl.chiSquareTest(double[],long[]) H2] tokens: 679 prompt + 109 completion = 788 total
  📊 GPT[method_score org.apache.commons.math.stat.inference.TestUtils.chiSquare(double[],long[]) H3] tokens: 637 prompt + 3 completion = 640 total
  📊 GPT[method_explanation org.apache.commons.math.stat.inference.TestUtils.chiSquare(double[],long[]) H3] tokens: 618 prompt + 114 completion = 732 total
  📊 GPT[method_score org.apache.commons.math.stat.inference.TestUtils.chiSquareTest(double[],long[]) H3] tokens: 629 prompt + 3 completion = 632 total
  📊 GPT[method_explanation org.apache.commons.math.stat.inference.TestUtils.chiSquareTest(double[],long[]) H3] tokens: 607 prompt + 129 completion = 736 total
  📊 GPT[method_score org.apache.commons.math.stat.inference.ChiSquareTestImpl.chiSquare(double[],long[]) H3] tokens: 794 prompt + 3 completion = 797 total
  📊 GPT[method_explanation org.apache.commons.math.stat.inference.ChiSquareTestImpl.chiSquare(double[],long[]) H3] tokens: 673 prompt + 108 completion = 781 total
  📊 GPT[method_score org.apache.commons.math.stat.inference.ChiSquareTestImpl.chiSquareTest(double[],long[]) H3] tokens: 730 prompt + 3 completion = 733 total
  📊 GPT[method_explanation org.apache.commons.math.stat.inference.ChiSquareTestImpl.chiSquareTest(double[],long[]) H3] tokens: 674 prompt + 110 completion = 784 total
  📊 GPT[method_score org.apache.commons.math.stat.inference.TestUtils.chiSquare(double[],long[]) H4] tokens: 637 prompt + 3 completion = 640 total
  📊 GPT[method_explanation org.apache.commons.math.stat.inference.TestUtils.chiSquare(double[],long[]) H4] tokens: 618 prompt + 118 completion = 736 total
  📊 GPT[method_score org.apache.commons.math.stat.inference.TestUtils.chiSquareTest(double[],long[]) H4] tokens: 629 prompt + 3 completion = 632 total
  📊 GPT[method_explanation org.apache.commons.math.stat.inference.TestUtils.chiSquareTest(double[],long[]) H4] tokens: 607 prompt + 129 completion = 736 total
  📊 GPT[method_score org.apache.commons.math.stat.inference.ChiSquareTestImpl.chiSquare(double[],long[]) H4] tokens: 794 prompt + 3 completion = 797 total
  📊 GPT[method_explanation org.apache.commons.math.stat.inference.ChiSquareTestImpl.chiSquare(double[],long[]) H4] tokens: 673 prompt + 139 completion = 812 total
  📊 GPT[method_score org.apache.commons.math.stat.inference.ChiSquareTestImpl.chiSquareTest(double[],long[]) H4] tokens: 730 prompt + 3 completion = 733 total
  📊 GPT[method_explanation org.apache.commons.math.stat.inference.ChiSquareTestImpl.chiSquareTest(double[],long[]) H4] tokens: 674 prompt + 137 completion = 811 total
  📊 GPT[method_score org.apache.commons.math.stat.inference.TestUtils.chiSquare(double[],long[]) H5] tokens: 636 prompt + 3 completion = 639 total
  📊 GPT[method_explanation org.apache.commons.math.stat.inference.TestUtils.chiSquare(double[],long[]) H5] tokens: 617 prompt + 108 completion = 725 total
  📊 GPT[method_score org.apache.commons.math.stat.inference.TestUtils.chiSquareTest(double[],long[]) H5] tokens: 628 prompt + 3 completion = 631 total
  📊 GPT[method_explanation org.apache.commons.math.stat.inference.TestUtils.chiSquareTest(double[],long[]) H5] tokens: 606 prompt + 147 completion = 753 total
  📊 GPT[method_score org.apache.commons.math.stat.inference.ChiSquareTestImpl.chiSquare(double[],long[]) H5] tokens: 793 prompt + 3 completion = 796 total
  📊 GPT[method_explanation org.apache.commons.math.stat.inference.ChiSquareTestImpl.chiSquare(double[],long[]) H5] tokens: 672 prompt + 140 completion = 812 total
  📊 GPT[method_score org.apache.commons.math.stat.inference.ChiSquareTestImpl.chiSquareTest(double[],long[]) H5] tokens: 729 prompt + 3 completion = 732 total
  📊 GPT[method_explanation org.apache.commons.math.stat.inference.ChiSquareTestImpl.chiSquareTest(double[],long[]) H5] tokens: 673 prompt + 120 completion = 793 total
  🔀 Tie-breaking 3 methods with score 0.800000
  📊 GPT[method_tie_break] tokens: 1797 prompt + 110 completion = 1907 total
  🔍 Raw tie-breaking response: ```json
[
  {"method": "org.apache.commons.math.stat.inference.ChiSquareTestImpl.chiSquareTest(double[],long[])", "tie_break_score": 0.95},
  {"method": "org.apache.commons.math.stat.inference.ChiSquareTestImpl.chiSquare(double[],long[])", "tie_break_score": 0.82},
  {"method": "org.apache.commons.math.stat.inference.TestUtils.chiSquareTest(double[],long[])", "tie_break_score": 0.65}
]
```
    ❌ JSON parse attempt 1 failed: Expecting value: line 1 column 1 (char 0)
    ✅ Successfully parsed JSON attempt 2
    🔍 Parsed object type: <class 'list'>
    🔍 Parsed object content: [{'method': 'org.apache.commons.math.stat.inference.ChiSquareTestImpl.chiSquareTest(double[],long[])', 'tie_break_score': 0.95}, {'method': 'org.apache.commons.math.stat.inference.ChiSquareTestImpl.chiSquare(double[],long[])', 'tie_break_score': 0.82}, {'method': 'org.apache.commons.math.stat.inference.TestUtils.chiSquareTest(double[],long[])', 'tie_break_score': 0.65}]
    🔍 Processing method: org.apache.commons.math.stat.inference.ChiSquareTestImpl.chiSquareTest(double[],long[]), value: 0.95 (type: <class 'float'>)
    🔍 Coerced to: 0.95
    📝 Recorded org.apache.commons.math.stat.inference.ChiSquareTestImpl.chiSquareTest(double[],long[]): 0.95 -> 0.95
    🔍 Processing method: org.apache.commons.math.stat.inference.ChiSquareTestImpl.chiSquare(double[],long[]), value: 0.82 (type: <class 'float'>)
    🔍 Coerced to: 0.82
    📝 Recorded org.apache.commons.math.stat.inference.ChiSquareTestImpl.chiSquare(double[],long[]): 0.82 -> 0.82
    🔍 Processing method: org.apache.commons.math.stat.inference.TestUtils.chiSquareTest(double[],long[]), value: 0.65 (type: <class 'float'>)
    🔍 Coerced to: 0.65
    📝 Recorded org.apache.commons.math.stat.inference.TestUtils.chiSquareTest(double[],long[]): 0.65 -> 0.65
  📊 Parsed tie-breaking scores: {'org.apache.commons.math.stat.inference.ChiSquareTestImpl.chiSquareTest(double[],long[])': 1.0, 'org.apache.commons.math.stat.inference.ChiSquareTestImpl.chiSquare(double[],long[])': 0.8631578947368421, 'org.apache.commons.math.stat.inference.TestUtils.chiSquareTest(double[],long[])': 0.6842105263157895}
  🎯 Tie-breaking scores: {'org.apache.commons.math.stat.inference.ChiSquareTestImpl.chiSquareTest(double[],long[])': 1.0, 'org.apache.commons.math.stat.inference.ChiSquareTestImpl.chiSquare(double[],long[])': 0.8631578947368421, 'org.apache.commons.math.stat.inference.TestUtils.chiSquareTest(double[],long[])': 0.6842105263157895}
    org.apache.commons.math.stat.inference.TestUtils.chiSquareTest(double[],long[]): 0.800000 + 0.006842 = 0.806842
    org.apache.commons.math.stat.inference.ChiSquareTestImpl.chiSquare(double[],long[]): 0.800000 + 0.008632 = 0.808632
    org.apache.commons.math.stat.inference.ChiSquareTestImpl.chiSquareTest(double[],long[]): 0.800000 + 0.010000 = 0.810000
  ✅ Final ranking after tie-breaking:
    1. org.apache.commons.math.stat.inference.ChiSquareTestImpl.chiSquareTest(double[],long[]): 0.810000
    2. org.apache.commons.math.stat.inference.ChiSquareTestImpl.chiSquare(double[],long[]): 0.808632
    3. org.apache.commons.math.stat.inference.TestUtils.chiSquareTest(double[],long[]): 0.806842

Top suspicious methods:
  1. org.apache.commons.math.stat.inference.ChiSquareTestImpl.chiSquareTest(double[],long[]): 0.810 — best hypothesis H1: Hypothesis H1: The failure may be caused by incorrect handling of floating-point precision in the calculation of the chi-square statistic for large datasets. (confidence 0.700); supporting class org.apache.commons.math.stat.inference.ChiSquareTestImpl (HH1)
      explanation: The method `org.apache.commons.math.stat.inference.ChiSquareTestImpl.chiSquareTest(double[], long[])` rescales the `expected` array to ensure that the sum of the expected and observed counts are equal, which could introduce floating-poin...
  2. org.apache.commons.math.stat.inference.ChiSquareTestImpl.chiSquare(double[],long[]): 0.809 — best hypothesis H1: Hypothesis H1: The failure may be caused by incorrect handling of floating-point precision in the calculation of the chi-square statistic for large datasets. (confidence 0.700); supporting class org.apache.commons.math.stat.inference.ChiSquareTestImpl (HH1)
      explanation: The method `org.apache.commons.math.stat.inference.ChiSquareTestImpl.chiSquare(double[], long[])` rescales the `expected` array to ensure that the sum of the expected and observed counts are equal, which could introduce floating-point pr...
  3. org.apache.commons.math.stat.inference.TestUtils.chiSquareTest(double[],long[]): 0.807 — best hypothesis H1: Hypothesis H1: The failure may be caused by incorrect handling of floating-point precision in the calculation of the chi-square statistic for large datasets. (confidence 0.700); supporting class org.apache.commons.math.stat.inference.TestUtils (HH4)
      explanation: The method `org.apache.commons.math.stat.inference.TestUtils.chiSquareTest(double[], long[])` directly delegates the computation to the `chiSquareTest` method of the `ChiSquareTestImpl` instance, using the provided `exp` and `obs` arrays...
  4. org.apache.commons.math.stat.inference.TestUtils.chiSquare(double[],long[]): 0.700 — best hypothesis H1: Hypothesis H1: The failure may be caused by incorrect handling of floating-point precision in the calculation of the chi-square statistic for large datasets. (confidence 0.700); supporting class org.apache.commons.math.stat.inference.TestUtils (HH4)
      explanation: The method `org.apache.commons.math.stat.inference.TestUtils.chiSquare(double[], long[])` directly calls `chiSquareTest.chiSquare(expected, observed)`, which computes the chi-square statistic. The failure context shows a significant disc...

📊 Token Usage Summary:
  Total API calls: 77
  Total tokens: 50,833
  Prompt tokens: 46,250
  Completion tokens: 4,583
Results written to defects4j_batch_results/Math-102_parallel_case/Math-102_parallel_answer.csv
Token usage written to defects4j_batch_results/Math-102_parallel_case/Math-102_token_usage.csv
Summary written to defects4j_batch_results/Math-102_parallel_case/Math-102_parallel_summary.md
